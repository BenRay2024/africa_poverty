{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Imports-and-Constants\" data-toc-modified-id=\"Imports-and-Constants-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports and Constants</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-the-dataset\" data-toc-modified-id=\"Prepare-the-dataset-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Prepare the dataset</a></span></li><li><span><a href=\"#Mask-out-cloud,-snow,-and-cloud-shadow\" data-toc-modified-id=\"Mask-out-cloud,-snow,-and-cloud-shadow-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Mask out cloud, snow, and cloud shadow</a></span></li><li><span><a href=\"#Multi-yr-composite\" data-toc-modified-id=\"Multi-yr-composite-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Multi-yr composite</a></span></li><li><span><a href=\"#Add-nightlight\" data-toc-modified-id=\"Add-nightlight-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Add nightlight</a></span></li><li><span><a href=\"#Add-topography\" data-toc-modified-id=\"Add-topography-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Add topography</a></span></li><li><span><a href=\"#Export-TF-Records\" data-toc-modified-id=\"Export-TF-Records-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Export TF Records</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Register a Gmail email address at [https://code.earthengine.google.com](https://code.earthengine.google.come). This process may take a couple of days. Without registration, the `ee.Initialize()` command below will throw an error message.\n",
    "2. Within your conda environment, run `earthengine activate` and follow the prompt. For more instructions, see [https://developers.google.com/earth-engine/python_install-conda.html](https://developers.google.com/earth-engine/python_install-conda.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This file must be run twice: once for DHS and once for LSMS.  Adjust the parameters below based on your personal Google Cloud Platform account.  Keep in mind that CSV_INPUT_PATH, GCS_FILE_PREFIX, and IS_DHS will require different values when exporting DHS data than when exporting LSMS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_INPUT_PATH = '../data/dhs_clusters.csv'  # The path to the survey CSV, located in this repo\n",
    "DHS_ASSET_ID = 'projects/ec985-thesis/assets/dhs_clusters'  # The survey ID in your GEE account\n",
    "GCS_BUCKET = 'dhs-imgs'  # A GCS bucket you own that will house data\n",
    "GCS_FILE_PREFIX = 'dhs_tfrecords_raw2/' # Will prefix file names, it is recommended that you use different folders for DHS and LSMS.\n",
    "IS_DHS = True # False for LSMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_DHS:\n",
    "    file_suffix = '_dhslocs_'\n",
    "else:\n",
    "    file_suffix = '_lsmslocs_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "import optical_datasources as optx\n",
    "import imgtools\n",
    "import ee_tf_exports as tf\n",
    "from ee_assets import upload_geojson_to_gee, asset_exists\n",
    "import ee_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=aiGVzpUDs3wGNJv2Iu0BP9Gh-hVUsw7XLpeBECre8ag&tc=wxQ57rvEueBoiCPKeRlSjNKrgJMhy4OmFG_z31kph9I&cc=aLYfEiITBWg4lhMMGr6f8mGsWSAHIkDozBBmV5mmeeg>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=aiGVzpUDs3wGNJv2Iu0BP9Gh-hVUsw7XLpeBECre8ag&tc=wxQ57rvEueBoiCPKeRlSjNKrgJMhy4OmFG_z31kph9I&cc=aLYfEiITBWg4lhMMGr6f8mGsWSAHIkDozBBmV5mmeeg</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AfJohXnTPGsWO3ZVzeGX2Npd76Lm5LLQS89_0tD_FSA77BC25rWQyLhJrnU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will upload the DHS CSV to your Google Earth Engine account\n",
    "if not asset_exists(DHS_ASSET_ID):\n",
    "    upload_geojson_to_gee(CSV_INPUT_PATH, DHS_ASSET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs = ee.FeatureCollection(DHS_ASSET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_oldest = dhs.filter([ee.Filter.gt('year', 2008), ee.Filter.lte('year', 2011)])  # [2009-2011] inclusive\n",
    "dhs_middle = dhs.filter([ee.Filter.gt('year', 2011), ee.Filter.lte('year', 2014)])  # [2012-2014] inclusive\n",
    "dhs_recent = dhs.filter(ee.Filter.gt('year', 2014))  # [2015-onwards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest size: 7129\n",
      "Middle size: 8499\n",
      "Recent size: 4041\n"
     ]
    }
   ],
   "source": [
    "print('Oldest size:', dhs_oldest.size().getInfo())\n",
    "print('Middle size:', dhs_middle.size().getInfo())\n",
    "print('Recent size:', dhs_recent.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mozambique',\n",
       " 'lesotho',\n",
       " 'uganda',\n",
       " 'ethiopia',\n",
       " 'malawi',\n",
       " 'senegal',\n",
       " 'tanzania',\n",
       " 'nigeria',\n",
       " 'zimbabwe',\n",
       " 'burkina_faso',\n",
       " 'rwanda',\n",
       " 'cameroon',\n",
       " 'angola',\n",
       " 'cote_d_ivoire',\n",
       " 'mali',\n",
       " 'benin',\n",
       " 'guinea',\n",
       " 'zambia',\n",
       " 'sierra_leone',\n",
       " 'togo',\n",
       " 'democratic_republic_of_congo',\n",
       " 'kenya',\n",
       " 'ghana']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "countries = dhs.distinct('country').aggregate_array('country').getInfo()\n",
    "display(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lx_median_2009-11_mozambique_dhslocs\n",
      "879\n",
      "lx_median_2009-11_lesotho_dhslocs\n",
      "395\n",
      "lx_median_2009-11_uganda_dhslocs\n",
      "570\n",
      "lx_median_2009-11_ethiopia_dhslocs\n",
      "571\n",
      "lx_median_2009-11_malawi_dhslocs\n",
      "827\n",
      "lx_median_2009-11_senegal_dhslocs\n",
      "385\n",
      "lx_median_2009-11_tanzania_dhslocs\n",
      "1031\n",
      "lx_median_2009-11_nigeria_dhslocs\n",
      "239\n",
      "lx_median_2009-11_zimbabwe_dhslocs\n",
      "393\n",
      "lx_median_2009-11_burkina_faso_dhslocs\n",
      "541\n",
      "lx_median_2009-11_rwanda_dhslocs\n",
      "492\n",
      "lx_median_2009-11_cameroon_dhslocs\n",
      "576\n",
      "lx_median_2009-11_angola_dhslocs\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "countries = dhs_oldest.distinct('country').aggregate_array('country').getInfo()\n",
    "for i in countries:\n",
    "    df = dhs_oldest.filter(ee.Filter.eq('country', i))\n",
    "    fname = 'lx_median_2009-11_'+i+'_dhslocs'\n",
    "    print(fname)\n",
    "    print(df.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lx_median_2012-14_senegal_dhslocs\n",
      "200\n",
      "lx_median_2012-14_cote_d_ivoire_dhslocs\n",
      "341\n",
      "lx_median_2012-14_mali_dhslocs\n",
      "413\n",
      "lx_median_2012-14_benin_dhslocs\n",
      "746\n",
      "lx_median_2012-14_guinea_dhslocs\n",
      "300\n",
      "lx_median_2012-14_malawi_dhslocs\n",
      "280\n",
      "lx_median_2012-14_zambia_dhslocs\n",
      "719\n",
      "lx_median_2012-14_sierra_leone_dhslocs\n",
      "435\n",
      "lx_median_2012-14_nigeria_dhslocs\n",
      "889\n",
      "lx_median_2012-14_togo_dhslocs\n",
      "330\n",
      "lx_median_2012-14_democratic_republic_of_congo_dhslocs\n",
      "492\n",
      "lx_median_2012-14_kenya_dhslocs\n",
      "1585\n",
      "lx_median_2012-14_uganda_dhslocs\n",
      "208\n",
      "lx_median_2012-14_lesotho_dhslocs\n",
      "399\n",
      "lx_median_2012-14_ghana_dhslocs\n",
      "422\n",
      "lx_median_2012-14_burkina_faso_dhslocs\n",
      "248\n",
      "lx_median_2012-14_rwanda_dhslocs\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "countries = dhs_middle.distinct('country').aggregate_array('country').getInfo()\n",
    "for i in countries:\n",
    "    df = dhs_middle.filter(ee.Filter.eq('country', i))\n",
    "    fname = 'lx_median_2012-14_'+i+'_dhslocs'\n",
    "    print(fname)\n",
    "    print(df.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lx_median_2015-17_kenya_dhslocs\n",
      "245\n",
      "lx_median_2015-17_nigeria_dhslocs\n",
      "322\n",
      "lx_median_2015-17_tanzania_dhslocs\n",
      "608\n",
      "lx_median_2015-17_angola_dhslocs\n",
      "625\n",
      "lx_median_2015-17_malawi_dhslocs\n",
      "850\n",
      "lx_median_2015-17_zimbabwe_dhslocs\n",
      "400\n",
      "lx_median_2015-17_mali_dhslocs\n",
      "177\n",
      "lx_median_2015-17_ethiopia_dhslocs\n",
      "622\n",
      "lx_median_2015-17_ghana_dhslocs\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "countries = dhs_recent.distinct('country').aggregate_array('country').getInfo()\n",
    "for i in countries:\n",
    "    df = dhs_recent.filter(ee.Filter.eq('country', i))\n",
    "    fname = 'lx_median_2015-17_'+i+'_dhslocs'\n",
    "    print(fname)\n",
    "    print(df.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask out cloud, snow, and cloud shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_qamask(scene):\n",
    "    '''\n",
    "    Pixel QA Bit Flags\n",
    "    Bit  Attribute\n",
    "    0    Fill\n",
    "    1    Clear\n",
    "    2    Water\n",
    "    3    Cloud Shadow\n",
    "    4    Snow\n",
    "    5    Cloud\n",
    "    '''\n",
    "    qa = scene.select('pixel_qa')\n",
    "    clear = qa.bitwiseAnd(2).neq(0)\n",
    "    clear = clear.updateMask(clear).rename(['pxqa_clear'])\n",
    "\n",
    "    water = qa.bitwiseAnd(4).neq(0)\n",
    "    water = water.updateMask(water).rename(['pxqa_water'])\n",
    "\n",
    "    cloud_shadow = qa.bitwiseAnd(8).eq(0)\n",
    "    cloud_shadow = cloud_shadow.updateMask(cloud_shadow).rename(['pxqa_cloudshadow'])\n",
    "\n",
    "    snow = qa.bitwiseAnd(16).eq(0)\n",
    "    snow = snow.updateMask(snow).rename(['pxqa_snow'])\n",
    "\n",
    "    cloud = qa.bitwiseAnd(32).eq(0)\n",
    "    cloud = cloud.updateMask(cloud).rename(['pxqa_cloud'])\n",
    "\n",
    "    masks = ee.Image.cat([\n",
    "        clear, water, cloud_shadow, snow,\n",
    "        cloud\n",
    "    ])\n",
    "\n",
    "        # return scene.select(scene.bandNames().remove('pixel_qa')).addBands(masks)\n",
    "    return masks\n",
    "\n",
    "def mask_qaclear(img):\n",
    "\n",
    "    clear_mask = decode_qamask(img).select('pxqa_clear')\n",
    "    cloudshadow_mask = decode_qamask(img).select('pxqa_cloudshadow')\n",
    "    snow_mask = decode_qamask(img).select('pxqa_snow')\n",
    "    cloud_mask = decode_qamask(img).select('pxqa_cloud')\n",
    "        \n",
    "    return img.updateMask(cloudshadow_mask).updateMask(snow_mask).updateMask(cloud_mask).updateMask(snow_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-yr composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selbands = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_recent = dhs_recent.geometry()\n",
    "srcoll_recent = ee_utils.LandsatSR(roi_recent, '2015-1-1', '2017-12-31').merged\n",
    "srcoll_recent = srcoll_recent.map(mask_qaclear).select(selbands)\n",
    "srmedian_recent = srcoll_recent.median().reproject('EPSG:3857', None, 30)\n",
    "srmedian_recent = ee_utils.add_latlon(srmedian_recent)\n",
    "\n",
    "# roi_recent = dhs_recent.geometry()\n",
    "# srcoll_recent = ee_utils.LandsatSR(roi_recent, '2015-1-1', '2017-12-31').merged\n",
    "# srcoll_recent = srcoll_recent.map(ee_utils.mask_qaclear).select(selbands)\n",
    "# srmedian_recent = srcoll_recent.median()\n",
    "# srmedian_recent = ee_utils.add_latlon(srmedian_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_middle = dhs_middle.geometry()\n",
    "srcoll_middle = optx.LandsatSR(roi_middle, '2012-1-1', '2014-12-31').merged\n",
    "srcoll_middle = srcoll_middle.map(mask_qaclear)\n",
    "srmedian_middle = srcoll_middle.select(selbands).median().reproject('EPSG:3857', None, 30)\n",
    "srmedian_middle = imgtools.add_latlon(srmedian_middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_oldest = dhs_oldest.geometry()\n",
    "srcoll_oldest = optx.LandsatSR(roi_oldest, '2009-1-1', '2011-12-31').merged\n",
    "srcoll_oldest = srcoll_oldest.map(mask_qaclear)\n",
    "srmedian_oldest = srcoll_oldest.select(selbands).median().reproject('EPSG:3857', None, 30)\n",
    "srmedian_oldest = imgtools.add_latlon(srmedian_oldest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add nightlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "viirs = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\")\n",
    "dmsp = ee.ImageCollection(\"NOAA/DMSP-OLS/CALIBRATED_LIGHTS_V4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlband = ['NIGHTLIGHTS']\n",
    "viirs_recent = viirs.filterDate('2015-1-1', '2017-12-31').median().select([0],nlband)\n",
    "viirs_mid = viirs.filterDate('2012-1-1', '2014-12-31').median().select([0],nlband)\n",
    "dmsp_oldest = dmsp.filterDate('2009-1-1', '2011-12-31').median().select([0],nlband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "srmedian_recent = srmedian_recent.addBands(viirs_recent.reproject('EPSG:3857', None, 30))\n",
    "srmedian_middle = srmedian_middle.addBands(viirs_mid.reproject('EPSG:3857', None, 30))\n",
    "srmedian_oldest = srmedian_oldest.addBands(dmsp_oldest.reproject('EPSG:3857', None, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = ee.Image(\"USGS/SRTMGL1_003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbands = ['ELEV','SLO', 'ASP']\n",
    "topogr = ee.Algorithms.Terrain(dem).select(['elevation', 'slope', 'aspect'], tbands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "srmedian_recent = srmedian_recent.addBands(topogr.reproject('EPSG:3857', None, 30))\n",
    "srmedian_middle = srmedian_middle.addBands(topogr.reproject('EPSG:3857', None, 30))\n",
    "srmedian_oldest = srmedian_oldest.addBands(topogr.reproject('EPSG:3857', None, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhsinfo = dhs_recent.first().propertyNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'year',\n",
       " 'wealthpooled',\n",
       " 'urban_rural',\n",
       " 'lon',\n",
       " 'households',\n",
       " 'lat',\n",
       " 'system:index']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhsinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lx_median_2015-17_Angola_dhslocs_\n",
      "['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'wealth', 'cluster', 'country', 'year', 'wealthpooled', 'cname', 'households', 'LATNUM', 'wealthpooled5country', 'hv000', 'URBAN_RURA', 'region', 'svyid', 'iso3n', 'system:index', 'iso3', 'LONGNUM', 'LAT', 'LON', 'ELEV', 'SLO', 'ASP', 'NIGHTLIGHTS']\n"
     ]
    }
   ],
   "source": [
    "countries = dhs_recent.distinct('country').aggregate_array('country').getInfo()\n",
    "for i in countries[0:1]:\n",
    "    seldhs = dhs_recent.filter(ee.Filter.eq('country', i))\n",
    "    fname = 'lx_median_2015-17_'+i+file_suffix\n",
    "    print(fname)\n",
    "    \n",
    "    bands = selbands+dhsinfo+['LAT', 'LON']+tbands+nlband\n",
    "    \n",
    "    test = tf.get_array_patches(srmedian_recent, 30, 127, seldhs, \n",
    "                                   True, True, bands, None, \n",
    "                                   GCS_BUCKET,\n",
    "                                   GCS_FILE_PREFIX, \n",
    "                                   fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lx_median_2012-14_Burkina Faso_dhslocs_\n",
      "['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'wealth', 'cluster', 'country', 'year', 'wealthpooled', 'cname', 'households', 'LATNUM', 'wealthpooled5country', 'hv000', 'URBAN_RURA', 'region', 'svyid', 'iso3n', 'system:index', 'iso3', 'LONGNUM', 'LAT', 'LON', 'ELEV', 'SLO', 'ASP', 'NIGHTLIGHTS']\n",
      "lx_median_2012-14_Benin_dhslocs_\n",
      "['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'wealth', 'cluster', 'country', 'year', 'wealthpooled', 'cname', 'households', 'LATNUM', 'wealthpooled5country', 'hv000', 'URBAN_RURA', 'region', 'svyid', 'iso3n', 'system:index', 'iso3', 'LONGNUM', 'LAT', 'LON', 'ELEV', 'SLO', 'ASP', 'NIGHTLIGHTS']\n",
      "lx_median_2012-14_Democratic Republic of Congo_dhslocs_\n",
      "['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'wealth', 'cluster', 'country', 'year', 'wealthpooled', 'cname', 'households', 'LATNUM', 'wealthpooled5country', 'hv000', 'URBAN_RURA', 'region', 'svyid', 'iso3n', 'system:index', 'iso3', 'LONGNUM', 'LAT', 'LON', 'ELEV', 'SLO', 'ASP', 'NIGHTLIGHTS']\n",
      "lx_median_2012-14_Congo_dhslocs_\n",
      "['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'wealth', 'cluster', 'country', 'year', 'wealthpooled', 'cname', 'households', 'LATNUM', 'wealthpooled5country', 'hv000', 'URBAN_RURA', 'region', 'svyid', 'iso3n', 'system:index', 'iso3', 'LONGNUM', 'LAT', 'LON', 'ELEV', 'SLO', 'ASP', 'NIGHTLIGHTS']\n",
      "lx_median_2012-14_Cote d'Ivoire_dhslocs_\n",
      "['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'wealth', 'cluster', 'country', 'year', 'wealthpooled', 'cname', 'households', 'LATNUM', 'wealthpooled5country', 'hv000', 'URBAN_RURA', 'region', 'svyid', 'iso3n', 'system:index', 'iso3', 'LONGNUM', 'LAT', 'LON', 'ELEV', 'SLO', 'ASP', 'NIGHTLIGHTS']\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "Invalid description. The description must contain only the following characters: a..z, A..Z, 0..9, \".\", \",\", \":\", \";\", \"_\" or \"-\". The description must be at most 100 characters long.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/ee/data.py:371\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/earthengine-legacy/table:export?alt=json returned \"Invalid description. The description must contain only the following characters: a..z, A..Z, 0..9, \".\", \",\", \":\", \";\", \"_\" or \"-\". The description must be at most 100 characters long.\". Details: \"Invalid description. The description must contain only the following characters: a..z, A..Z, 0..9, \".\", \",\", \":\", \";\", \"_\" or \"-\". The description must be at most 100 characters long.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(fname)\n\u001b[1;32m      7\u001b[0m bands \u001b[38;5;241m=\u001b[39m selbands\u001b[38;5;241m+\u001b[39mdhsinfo\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLON\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mtbands\u001b[38;5;241m+\u001b[39mnlband\n\u001b[0;32m----> 9\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_array_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrmedian_middle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m127\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseldhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mGCS_BUCKET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mGCS_FILE_PREFIX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documents/HARVARD/EC_985/africa_poverty/download/ee_tf_exports.py:74\u001b[0m, in \u001b[0;36mget_array_patches\u001b[0;34m(img, scale, ksize, points, doexport, tocloud, selectors, dropselectors, mybucket, prefix, fname)\u001b[0m\n\u001b[1;32m     68\u001b[0m patches_samps \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m pt: _sample_patch(pt, patches_array, scale))\u001b[38;5;241m.\u001b[39mflatten();\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doexport:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Export to a TFRecord file in Cloud Storage, creating a file\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# at gs://mybucket/prefix/fname.tfrecord\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# which you can load directly in TensorFlow.\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mtfexporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches_samps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtocloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropselectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmybucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patches_samps\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documents/HARVARD/EC_985/africa_poverty/download/ee_tf_exports.py:38\u001b[0m, in \u001b[0;36mtfexporter\u001b[0;34m(samples, tocloud, selectors, dropselectors, mybucket, prefix, fname)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     task \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mExport\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mtoDrive(\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m         collection\u001b[38;5;241m=\u001b[39msamples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m     )\n\u001b[0;32m---> 38\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m task\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/ee/batch.py:129\u001b[0m, in \u001b[0;36mTask.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m   result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mexportMap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m Task\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mEXPORT_TABLE:\n\u001b[0;32m--> 129\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexportTable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m Task\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mEXPORT_VIDEO:\n\u001b[1;32m    131\u001b[0m   result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mexportVideo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/ee/data.py:1714\u001b[0m, in \u001b[0;36mexportTable\u001b[0;34m(request_id, params)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Starts a table export task running.\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m \n\u001b[1;32m   1695\u001b[0m \u001b[38;5;124;03mThis is a low-level method. The higher-level ee.batch.Export.table object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;124;03m  If you are using the cloud API, this will be an Operation.\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 1714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prepare_and_run_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/ee/data.py:1804\u001b[0m, in \u001b[0;36m_prepare_and_run_export\u001b[0;34m(request_id, params, export_endpoint)\u001b[0m\n\u001b[1;32m   1801\u001b[0m   params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m serializer\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m   1802\u001b[0m       params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m], for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1803\u001b[0m num_retries \u001b[38;5;241m=\u001b[39m MAX_RETRIES \u001b[38;5;28;01mif\u001b[39;00m request_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-m1tf/lib/python3.9/site-packages/ee/data.py:373\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 373\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[0;31mEEException\u001b[0m: Invalid description. The description must contain only the following characters: a..z, A..Z, 0..9, \".\", \",\", \":\", \";\", \"_\" or \"-\". The description must be at most 100 characters long."
     ]
    }
   ],
   "source": [
    "countries = dhs_middle.distinct('country').aggregate_array('country').getInfo()\n",
    "for i in countries:\n",
    "    seldhs = dhs_middle.filter(ee.Filter.eq('country', i))\n",
    "    fname = 'lx_median_2012-14_'+i+file_suffix\n",
    "    print(fname)\n",
    "    \n",
    "    bands = selbands+dhsinfo+['LAT', 'LON']+tbands+nlband\n",
    "    \n",
    "    test = tf.get_array_patches(srmedian_middle, 30, 127, seldhs, \n",
    "                                   True, True, bands, None, \n",
    "                                   GCS_BUCKET,\n",
    "                                   GCS_FILE_PREFIX, \n",
    "                                   fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = dhs_oldest.distinct('country').aggregate_array('country').getInfo()\n",
    "for i in countries:\n",
    "    seldhs = dhs_oldest.filter(ee.Filter.eq('country', i))\n",
    "    fname = 'lx_median_2009-11_'+i+file_suffix\n",
    "    print(fname)\n",
    "    \n",
    "    bands = selbands+dhsinfo+['LAT', 'LON']+tbands+nlband\n",
    "    \n",
    "    test = tf.get_array_patches(srmedian_oldest, 30, 127, seldhs, \n",
    "                                   True, True, bands, None, \n",
    "                                   GCS_BUCKET,\n",
    "                                   GCS_FILE_PREFIX, \n",
    "                                   fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-m1tf",
   "language": "python",
   "name": "learn-env-m1tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
